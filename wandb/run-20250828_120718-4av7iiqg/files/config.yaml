_wandb:
    value:
        cli_version: 0.21.1
        e:
            ki7fyqdjjsem1jaeuvrxshdu27zhnqzz:
                codePath: train_cifar.py
                codePathLocal: train_cifar.py
                cpu_count: 64
                cpu_count_logical: 128
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "32212254720"
                        used: "23095504896"
                email: julio1@sjtu.edu.cn
                executable: /root/miniconda3/bin/python
                git:
                    commit: c06f031b0b6f6132ebea890b9e900cd22ace8e0b
                    remote: https://github.com/Misterursw/vit.git
                gpu: NVIDIA H20
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Hopper
                      cudaCores: 9984
                      memoryTotal: "102625181696"
                      name: NVIDIA H20
                      uuid: GPU-0321b259-1d9f-f47b-9f1c-f381a0b64cc8
                host: autodl-container-6ab54fbc91-acff8d23
                memory:
                    total: "1330811748352"
                os: Linux-5.15.0-130-generic-x86_64-with-glibc2.35
                program: /root/autodl-tmp/HRM/train_cifar.py
                python: CPython 3.12.3
                root: /root/autodl-tmp/HRM
                startedAt: "2025-08-28T04:07:18.740898Z"
                writerId: ki7fyqdjjsem1jaeuvrxshdu27zhnqzz
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 41
            "2":
                - 1
                - 41
            "3":
                - 13
                - 16
            "4": 3.12.3
            "5": 0.21.1
            "12": 0.21.1
            "13": linux-x86_64
model:
    value:
        H_cycles: 2
        H_layers: 6
        L_cycles: 2
        L_layers: 6
        expansion: 4
        forward_dtype: float32
        halt_exploration_prob: 0.1
        halt_max_steps: 16
        hidden_size: 512
        image_size: 32
        in_chans: 3
        num_classes: 100
        num_heads: 8
        patch_size: 4
        pos_encodings: learned
        rms_norm_eps: 1e-05
run:
    value:
        checkpoint_path: /root/autodl-tmp/checkpoints
        device: cuda
training:
    value:
        act_loss:
            trigger_accuracy_threshold: 40
            warmup_epochs: 200
        augmentation_type: autoaugment
        batch_size: 2048
        beta1: 0.9
        beta2: 0.95
        data_path: /root/autodl-tmp/data
        early_stopping_patience: 10
        epochs: 2000
        learning_rate: 0.0001
        lr_scheduler: cosine
        num_workers: 16
        optimizer: AdamW
        validation_interval: 5
        warmup_epochs: 10
        weight_decay: 0.05
wandb:
    value:
        entity: null
        name: run_v1
        project: hr-vit-cifar100-act
